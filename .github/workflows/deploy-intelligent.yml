name: Intelligent Deploy to Droplet

on:
  push:
    branches: [main]
    paths:
      - "agent_*/**"
      - "shared/**"
      - "config/**"
      - "deploy/docker-compose.yml"
      - ".github/workflows/deploy-intelligent.yml"
  workflow_dispatch:
    inputs:
      deploy_type:
        description: "Deployment type"
        required: false
        default: "auto"
        type: choice
        options:
          - auto
          - config
          - full
          - quick

env:
  DROPLET_HOST: root@45.55.173.72
  DEPLOY_PATH: /opt/code-chef
  DROPLET_IP: 45.55.173.72
  HEALTH_CHECK_TIMEOUT: 90
  HEALTH_CHECK_INTERVAL: 5

jobs:
  prepare-env:
    name: Prepare Environment
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Create .env file
        run: |
          # Create fresh .env from template (contains default values)
          cp config/env/.env.template config/env/.env

          # Create temporary file for secrets (will be merged)
          cat > /tmp/secrets.env << 'EOF'
          # === SECRETS FROM GITHUB (Overrides template defaults) ===
          # Orchestrator API Security
          ORCHESTRATOR_API_KEY=${{ secrets.ORCHESTRATOR_API_KEY }}
          # LLM & Tracing
          LANGCHAIN_API_KEY=${{ secrets.LANGSMITH_API_KEY }}
          LANGSMITH_API_KEY=${{ secrets.LANGSMITH_API_KEY }}
          LANGSMITH_WORKSPACE_ID=${{ secrets.LANGSMITH_WORKSPACE_ID }}
          # OpenRouter (Multi-Model LLM Gateway)
          OPENROUTER_API_KEY=${{ secrets.OPENROUTER_API_KEY }}
          # LLM Provider Keys
          CLAUDE_API_KEY=${{ secrets.CLAUDE_API_KEY }}
          MISTRAL_API_KEY=${{ secrets.MISTRAL_API_KEY }}
          PERPLEXITY_API_KEY=${{ secrets.PERPLEXITY_API_KEY }}
          # Linear Integration
          LINEAR_TEAM_ID=${{ secrets.LINEAR_TEAM_ID }}
          LINEAR_API_KEY=${{ secrets.LINEAR_OAUTH_DEV_TOKEN }}
          LINEAR_OAUTH_DEV_TOKEN=${{ secrets.LINEAR_OAUTH_DEV_TOKEN }}
          LINEAR_WEBHOOK_SIGNING_SECRET=${{ secrets.LINEAR_WEBHOOK_SIGNING_SECRET }}
          # RAG/Qdrant
          QDRANT_URL=${{ secrets.QDRANT_URL }}
          QDRANT_API_KEY=${{ secrets.QDRANT_API_KEY }}
          OPENAI_API_KEY=${{ secrets.OPENAI_API_KEY }}
          # Database
          DB_PASSWORD=${{ secrets.DB_PASSWORD }}
          # OAuth Configuration
          GITHUB_OAUTH_CLIENT_SECRET=${{ secrets.GH_OAUTH_CLIENT_SECRET }}
          OAUTH2_PROXY_CLIENT_ID=${{ secrets.OAUTH2_PROXY_CLIENT_ID }}
          OAUTH2_PROXY_CLIENT_SECRET=${{ secrets.OAUTH2_PROXY_CLIENT_SECRET }}
          OAUTH2_PROXY_COOKIE_SECRET=${{ secrets.OAUTH2_PROXY_COOKIE_SECRET }}
          OAUTH2_PROXY_EMAIL_DOMAINS=*
          # Grafana Cloud
          GRAFANA_CLOUD_API_TOKEN=${{ secrets.GRAFANA_CLOUD_API_TOKEN }}
          # Supabase
          SUPABASE_SERVICE_ROLE_KEY=${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
          # HuggingFace (ModelOps)
          HUGGINGFACE_TOKEN=${{ secrets.HUGGINGFACE_TOKEN }}
          EOF

          # Merge secrets into .env, replacing duplicates (secrets override template)
          while IFS='=' read -r key value; do
            # Skip comments (lines starting with #) and empty lines
            [[ "$key" =~ ^[[:space:]]*# || -z "$key" ]] && continue
            # Remove existing key from .env (prevents duplicates)
            # Escape special regex characters in key name
            escaped_key=$(printf '%s\n' "$key" | sed 's:[][\\/.^$*]:\\&:g')
            sed -i "/^${escaped_key}=/d" config/env/.env
          done < /tmp/secrets.env

          # Append all secrets
          cat /tmp/secrets.env >> config/env/.env

          # Validate: Check for duplicate keys
          echo "ðŸ” Validating .env file for duplicates..."
          duplicates=$(grep -v '^#' config/env/.env | grep -v '^$' | cut -d= -f1 | sort | uniq -d)
          if [ -n "$duplicates" ]; then
            echo "âŒ DUPLICATE KEYS FOUND:"
            echo "$duplicates"
            echo "Full .env content:"
            cat config/env/.env
            exit 1
          fi

          # Verify critical variables present
          echo "âœ… Checking critical variables..."
          for var in LLM_PROVIDER OPENROUTER_API_KEY LANGSMITH_API_KEY; do
            if ! grep -q "^${var}=" config/env/.env; then
              echo "âŒ Missing critical variable: ${var}"
              exit 1
            fi
          done

          # Show summary
          echo "âœ… .env file created successfully"
          echo "ðŸ“Š Total variables: $(grep -v '^#' config/env/.env | grep -v '^$' | wc -l)"
          echo "ðŸ”‘ LLM_PROVIDER: $(grep '^LLM_PROVIDER=' config/env/.env | cut -d= -f2)"
          ls -la config/env/.env

      - name: Upload .env as artifact
        uses: actions/upload-artifact@v4
        with:
          name: env-file
          path: config/env/.env
          retention-days: 1
          include-hidden-files: true

  detect-changes:
    name: Detect Change Type
    runs-on: ubuntu-latest
    outputs:
      deploy_strategy: ${{ steps.strategy.outputs.strategy }}
      has_code_changes: ${{ steps.classify.outputs.has_code_changes }}
      has_config_changes: ${{ steps.classify.outputs.has_config_changes }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 2

      - name: Get changed files
        id: changed-files
        uses: tj-actions/changed-files@v40
        with:
          files_yaml: |
            code:
              - 'agent_*/**/*.py'
              - 'shared/**/*.py'
              - '**/Dockerfile'
              - '**/requirements.txt'
              - 'deploy/docker-compose.yml'
            config:
              - 'config/env/*.env'
              - 'config/**/*.yaml'
              - 'config/**/*.yml'

      - name: Classify changes
        id: classify
        run: |
          if [ "${{ steps.changed-files.outputs.code_any_changed }}" == "true" ]; then
            echo "has_code_changes=true" >> $GITHUB_OUTPUT
          else
            echo "has_code_changes=false" >> $GITHUB_OUTPUT
          fi

          if [ "${{ steps.changed-files.outputs.config_any_changed }}" == "true" ]; then
            echo "has_config_changes=true" >> $GITHUB_OUTPUT
          else
            echo "has_config_changes=false" >> $GITHUB_OUTPUT
          fi

      - name: Determine strategy
        id: strategy
        run: |
          # Manual override from workflow_dispatch
          if [ "${{ github.event.inputs.deploy_type }}" != "" ]; then
            echo "strategy=${{ github.event.inputs.deploy_type }}" >> $GITHUB_OUTPUT
            echo "Manual override: ${{ github.event.inputs.deploy_type }}"
            exit 0
          fi

          # Auto-detect based on changes
          if [ "${{ steps.classify.outputs.has_code_changes }}" == "true" ]; then
            echo "strategy=full" >> $GITHUB_OUTPUT
            echo "Code changes detected â†’ FULL rebuild"
          elif [ "${{ steps.classify.outputs.has_config_changes }}" == "true" ]; then
            echo "strategy=config" >> $GITHUB_OUTPUT
            echo "Config-only changes â†’ FAST deployment"
          else
            echo "strategy=quick" >> $GITHUB_OUTPUT
            echo "No critical changes â†’ QUICK restart"
          fi

  deploy-config:
    name: Deploy Config Changes
    runs-on: ubuntu-latest
    needs: [detect-changes, prepare-env]
    if: needs.detect-changes.outputs.deploy_strategy == 'config'

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure SSH
        run: |
          mkdir -p ~/.ssh
          echo "${{ secrets.DROPLET_SSH_KEY }}" > ~/.ssh/id_ed25519
          chmod 600 ~/.ssh/id_ed25519
          ssh-keyscan -H ${{ env.DROPLET_IP }} >> ~/.ssh/known_hosts

      - name: Download .env from artifact
        uses: actions/download-artifact@v4
        with:
          name: env-file
          path: config/env/

      - name: Upload .env to droplet (with backup)
        run: |
          # Backup existing .env on droplet
          ssh ${{ env.DROPLET_HOST }} "cd ${{ env.DEPLOY_PATH }}/config/env && \
            if [ -f .env ]; then \
              cp .env .env.backup-\$(date +%Y%m%d-%H%M%S); \
              echo 'ðŸ“¦ Backed up existing .env'; \
            fi"

          # Upload new .env (overwrites completely)
          scp config/env/.env ${{ env.DROPLET_HOST }}:${{ env.DEPLOY_PATH }}/config/env/.env

          # Verify upload and check for duplicates on droplet
          ssh ${{ env.DROPLET_HOST }} "cd ${{ env.DEPLOY_PATH }}/config/env && \
            echo 'ðŸ” Verifying uploaded .env...' && \
            duplicates=\$(grep -v '^#' .env | grep -v '^$' | cut -d= -f1 | sort | uniq -d) && \
            if [ -n \"\$duplicates\" ]; then \
              echo 'âŒ DUPLICATE KEYS FOUND ON DROPLET:'; \
              echo \"\$duplicates\"; \
              exit 1; \
            fi && \
            echo 'âœ… .env validated on droplet' && \
            echo 'ðŸ”‘ LLM_PROVIDER:' \$(grep '^LLM_PROVIDER=' .env | cut -d= -f2)"

      - name: Pull latest code on droplet
        run: |
          ssh ${{ env.DROPLET_HOST }} "cd ${{ env.DEPLOY_PATH }} && git stash && git pull origin main"

      - name: Restart services (down+up to reload env)
        run: |
          ssh ${{ env.DROPLET_HOST }} "cd ${{ env.DEPLOY_PATH }}/deploy && \
            docker compose down --remove-orphans --volumes && \
            docker container prune -f && \
            docker compose up -d && \
            docker image prune -f --filter 'dangling=true'"

      - name: Wait for services and health check
        run: |
          echo "ðŸ” Waiting for services to start (max ${{ env.HEALTH_CHECK_TIMEOUT }}s)..."
          max_attempts=$((${{ env.HEALTH_CHECK_TIMEOUT }} / ${{ env.HEALTH_CHECK_INTERVAL }}))

          for i in $(seq 1 $max_attempts); do
            sleep ${{ env.HEALTH_CHECK_INTERVAL }}
            all_healthy=true
            failed_services=""
            
            for port in 8001 8007 8008 8010; do
              response=$(ssh ${{ env.DROPLET_HOST }} "curl -sf http://localhost:${port}/health 2>/dev/null" || echo "")
              status=$(echo "$response" | jq -r '.status // empty' 2>/dev/null || echo "")
              
              if [ "$status" != "healthy" ] && [ "$status" != "ok" ]; then
                all_healthy=false
                failed_services="${failed_services} ${port}"
              else
                echo "  âœ“ Port ${port}: ${status}"
              fi
            done
            
            if [ "$all_healthy" == "true" ]; then
              echo "âœ… All services healthy after $((i * ${{ env.HEALTH_CHECK_INTERVAL }})) seconds"
              exit 0
            fi
            
            echo "â³ Attempt $i/$max_attempts: Waiting for:$failed_services"
          done

          echo "âŒ Services failed to become healthy within ${{ env.HEALTH_CHECK_TIMEOUT }}s"
          echo "ðŸ“‹ Checking logs..."
          ssh ${{ env.DROPLET_HOST }} "cd ${{ env.DEPLOY_PATH }}/deploy && docker compose logs --tail=50"
          exit 1

  deploy-full:
    name: Deploy with Full Rebuild
    runs-on: ubuntu-latest
    needs: [detect-changes, prepare-env]
    if: needs.detect-changes.outputs.deploy_strategy == 'full'

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Configure SSH
        run: |
          mkdir -p ~/.ssh
          echo "${{ secrets.DROPLET_SSH_KEY }}" > ~/.ssh/id_ed25519
          chmod 600 ~/.ssh/id_ed25519
          ssh-keyscan -H ${{ env.DROPLET_IP }} >> ~/.ssh/known_hosts

      - name: Download .env from artifact
        uses: actions/download-artifact@v4
        with:
          name: env-file
          path: config/env/

      - name: Upload .env to droplet (with backup)
        run: |
          # Backup existing .env on droplet
          ssh ${{ env.DROPLET_HOST }} "cd ${{ env.DEPLOY_PATH }}/config/env && \
            if [ -f .env ]; then \
              cp .env .env.backup-\$(date +%Y%m%d-%H%M%S); \
              echo 'ðŸ“¦ Backed up existing .env'; \
            fi"

          # Upload new .env (overwrites completely)
          scp config/env/.env ${{ env.DROPLET_HOST }}:${{ env.DEPLOY_PATH }}/config/env/.env

          # Verify upload and check for duplicates on droplet
          ssh ${{ env.DROPLET_HOST }} "cd ${{ env.DEPLOY_PATH }}/config/env && \
            echo 'ðŸ” Verifying uploaded .env...' && \
            duplicates=\$(grep -v '^#' .env | grep -v '^$' | cut -d= -f1 | sort | uniq -d) && \
            if [ -n \"\$duplicates\" ]; then \
              echo 'âŒ DUPLICATE KEYS FOUND ON DROPLET:'; \
              echo \"\$duplicates\"; \
              exit 1; \
            fi && \
            echo 'âœ… .env validated on droplet' && \
            echo 'ðŸ”‘ LLM_PROVIDER:' \$(grep '^LLM_PROVIDER=' .env | cut -d= -f2)"

      - name: Pull and rebuild on droplet
        run: |
          ssh ${{ env.DROPLET_HOST }} "cd ${{ env.DEPLOY_PATH }} && \
            git pull origin main && \
            cd deploy && \
            docker compose down --remove-orphans --volumes && \
            docker container prune -f && \
            DOCKER_BUILDKIT=1 docker compose build --build-arg BUILDKIT_INLINE_CACHE=1 && \
            docker compose up -d && \
            docker image prune -af --filter 'until=24h' && \
            docker builder prune -af --filter 'until=24h'"

      - name: Wait for services and health check
        run: |
          echo "ðŸ” Waiting for services to start (max ${{ env.HEALTH_CHECK_TIMEOUT }}s)..."
          max_attempts=$((${{ env.HEALTH_CHECK_TIMEOUT }} / ${{ env.HEALTH_CHECK_INTERVAL }}))

          for i in $(seq 1 $max_attempts); do
            sleep ${{ env.HEALTH_CHECK_INTERVAL }}
            all_healthy=true
            failed_services=""
            
            for port in 8001 8007 8008 8010; do
              response=$(ssh ${{ env.DROPLET_HOST }} "curl -sf http://localhost:${port}/health 2>/dev/null" || echo "")
              status=$(echo "$response" | jq -r '.status // empty' 2>/dev/null || echo "")
              
              if [ "$status" != "healthy" ] && [ "$status" != "ok" ]; then
                all_healthy=false
                failed_services="${failed_services} ${port}"
              else
                echo "  âœ“ Port ${port}: ${status}"
              fi
            done
            
            if [ "$all_healthy" == "true" ]; then
              echo "âœ… All services healthy after $((i * ${{ env.HEALTH_CHECK_INTERVAL }})) seconds"
              exit 0
            fi
            
            echo "â³ Attempt $i/$max_attempts: Waiting for:$failed_services"
          done

          echo "âŒ Services failed to become healthy within ${{ env.HEALTH_CHECK_TIMEOUT }}s"
          echo "ðŸ“‹ Checking logs..."
          ssh ${{ env.DROPLET_HOST }} "cd ${{ env.DEPLOY_PATH }}/deploy && docker compose logs --tail=50"
          exit 1

      - name: Cleanup on failure
        if: failure()
        run: |
          ssh ${{ env.DROPLET_HOST }} "docker system prune --volumes --force"

  deploy-quick:
    name: Quick Restart
    runs-on: ubuntu-latest
    needs: detect-changes
    if: needs.detect-changes.outputs.deploy_strategy == 'quick'

    steps:
      - name: Configure SSH
        run: |
          mkdir -p ~/.ssh
          echo "${{ secrets.DROPLET_SSH_KEY }}" > ~/.ssh/id_ed25519
          chmod 600 ~/.ssh/id_ed25519
          ssh-keyscan -H ${{ env.DROPLET_IP }} >> ~/.ssh/known_hosts

      - name: Pull latest code
        run: |
          ssh ${{ env.DROPLET_HOST }} "cd ${{ env.DEPLOY_PATH }} && git pull origin main"

      - name: Quick restart
        run: |
          ssh ${{ env.DROPLET_HOST }} "cd ${{ env.DEPLOY_PATH }}/deploy && \
            docker compose restart && \
            docker image prune -f --filter 'dangling=true'"

      - name: Wait for services and health check
        run: |
          echo "ðŸ” Waiting for services to start (max 60s for quick restart)..."
          max_attempts=12

          for i in $(seq 1 $max_attempts); do
            sleep 5
            all_healthy=true
            failed_services=""
            
            for port in 8001 8007 8008 8010; do
              response=$(ssh ${{ env.DROPLET_HOST }} "curl -sf http://localhost:${port}/health 2>/dev/null" || echo "")
              status=$(echo "$response" | jq -r '.status // empty' 2>/dev/null || echo "")
              
              if [ "$status" != "healthy" ] && [ "$status" != "ok" ]; then
                all_healthy=false
                failed_services="${failed_services} ${port}"
              else
                echo "  âœ“ Port ${port}: ${status}"
              fi
            done
            
            if [ "$all_healthy" == "true" ]; then
              echo "âœ… All services healthy after $((i * 5)) seconds"
              exit 0
            fi
            
            echo "â³ Attempt $i/$max_attempts: Waiting for:$failed_services"
          done

          echo "âŒ Services failed to become healthy within 60s"
          echo "ðŸ“‹ Checking logs..."
          ssh ${{ env.DROPLET_HOST }} "cd ${{ env.DEPLOY_PATH }}/deploy && docker compose logs --tail=50"
          exit 1

  notify:
    name: Deployment Notification
    runs-on: ubuntu-latest
    needs:
      [detect-changes, prepare-env, deploy-config, deploy-full, deploy-quick]
    if: always()

    steps:
      - name: Summary
        run: |
          echo "## ðŸš€ Deployment Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Strategy**: ${{ needs.detect-changes.outputs.deploy_strategy }}" >> $GITHUB_STEP_SUMMARY
          echo "**Status**: ${{ job.status }}" >> $GITHUB_STEP_SUMMARY
          echo "**Code Changes:** ${{ needs.detect-changes.outputs.has_code_changes }}" >> $GITHUB_STEP_SUMMARY
          echo "**Config Changes:** ${{ needs.detect-changes.outputs.has_config_changes }}" >> $GITHUB_STEP_SUMMARY
          echo "**Timestamp**: $(date -u)" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          if [ "${{ needs.deploy-config.result }}" == "success" ] || \
             [ "${{ needs.deploy-full.result }}" == "success" ] || \
             [ "${{ needs.deploy-quick.result }}" == "success" ]; then
            echo "âœ… **Deployment successful**" >> $GITHUB_STEP_SUMMARY
          else
            echo "âŒ **Deployment failed**" >> $GITHUB_STEP_SUMMARY
          fi

      - name: Trigger cleanup workflow
        if: success()
        continue-on-error: true
        uses: actions/github-script@v7
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            await github.rest.actions.createWorkflowDispatch({
              owner: context.repo.owner,
              repo: context.repo.repo,
              workflow_id: 'cleanup-docker-resources.yml',
              ref: 'main',
              inputs: {
                cleanup_type: 'standard'
              }
            });
