# Droplet Memory Crisis - Recovery Guide

## üö® Current Issue: Out of Memory (OOM)

Your droplet console shows multiple processes being killed:

- Node processes (total-vm: 4493MB, 4475MB)
- Snap daemon processes

**Root Cause:** The 2GB droplet is running out of memory with all services running.

---

## üîß Immediate Recovery Steps (In Console)

You're in recovery mode. Run these commands:

### 1. Check Current Memory Usage

```bash
free -h
df -h
```

### 2. Check Which Services Are Running

```bash
systemctl list-units --type=service --state=running
```

### 3. Stop All Docker Services Temporarily

```bash
cd /opt/Dev-Tools/compose
docker-compose down
```

This will free up memory immediately.

### 4. Add Swap Space (Critical!)

```bash
# Check if swap exists
swapon --show

# If no swap, create 4GB swap file
fallocate -l 4G /swapfile
chmod 600 /swapfile
mkswap /swapfile
swapon /swapfile

# Make it permanent
echo '/swapfile none swap sw 0 0' >> /etc/fstab

# Verify
free -h
```

### 5. Optimize Docker Memory Limits

Edit the docker-compose file to add memory limits:

```bash
cd /opt/Dev-Tools/compose
nano docker-compose.yml
```

Add this to each service:

```yaml
deploy:
  resources:
    limits:
      memory: 256M
    reservations:
      memory: 128M
```

### 6. Start Services Gradually

```bash
# Start infrastructure first
docker-compose up -d postgres qdrant

# Wait 30 seconds
sleep 30

# Start gateway
docker-compose up -d gateway-mcp

# Wait 30 seconds
sleep 30

# Start core agents one by one
docker-compose up -d orchestrator
sleep 15
docker-compose up -d feature-dev
sleep 15
docker-compose up -d code-review
```

---

## üí° Memory Optimization Strategy

### Option 1: Add Swap (Done Above)

- 4GB swap gives you breathing room
- Slower than RAM but prevents crashes

### Option 2: Reduce Service Count

Only run essential services:

```bash
# Minimal stack (1.2GB total)
docker-compose up -d postgres gateway-mcp orchestrator feature-dev
```

### Option 3: Upgrade Droplet

Recommended: 4GB RAM ($24/month)

```bash
# From DigitalOcean console:
# 1. Power off droplet
# 2. Resize to 4GB plan
# 3. Power on
```

---

## üìä Memory Budget (2GB Droplet)

**Current Services (estimated):**

- System: ~200MB
- Docker daemon: ~100MB
- PostgreSQL: ~150MB
- Qdrant: ~200MB
- Gateway (Node): ~150MB
- Orchestrator: ~200MB
- Feature-Dev: ~200MB
- Code-Review: ~150MB
- Infrastructure: ~150MB
- CI/CD: ~150MB
- Documentation: ~150MB
- RAG: ~200MB
- **Total: ~2.0GB** ‚ö†Ô∏è TOO MUCH!

**With Swap + Memory Limits:**

- Each agent limited to 256MB
- Swap handles overflow
- Should be stable

---

## üîç Check What's Using Memory

```bash
# Top memory consumers
ps aux --sort=-%mem | head -20

# Docker container stats
docker stats --no-stream

# System memory details
cat /proc/meminfo
```

---

## ‚ö° Quick Commands Reference

```bash
# Emergency: Stop everything
docker-compose -f /opt/Dev-Tools/compose/docker-compose.yml down

# Add swap
fallocate -l 4G /swapfile && chmod 600 /swapfile && mkswap /swapfile && swapon /swapfile

# Start minimal services
cd /opt/Dev-Tools/compose
docker-compose up -d postgres gateway-mcp orchestrator

# Check memory
free -h && docker stats --no-stream

# View logs for OOM issues
dmesg | grep -i "out of memory"
journalctl -u docker --since "1 hour ago" | grep -i oom
```

---

## üéØ Recommended Solution

1. **Add 4GB swap** (immediate relief)
2. **Update docker-compose.yml** with memory limits
3. **Start only essential services** for now
4. **Upgrade to 4GB droplet** when ready

---

## üìù Memory-Limited docker-compose.yml

Here's a minimal configuration for 2GB droplet:

```yaml
services:
  postgres:
    # ... existing config ...
    deploy:
      resources:
        limits:
          memory: 200M
        reservations:
          memory: 100M

  gateway-mcp:
    # ... existing config ...
    deploy:
      resources:
        limits:
          memory: 150M
        reservations:
          memory: 100M

  orchestrator:
    # ... existing config ...
    deploy:
      resources:
        limits:
          memory: 256M
        reservations:
          memory: 128M

  feature-dev:
    # ... existing config ...
    deploy:
      resources:
        limits:
          memory: 256M
        reservations:
          memory: 128M
```

---

## üöÄ After Recovery: Deploy Frontend

Once services are stable:

```bash
cd /opt/Dev-Tools
git pull origin main
cd compose
docker-compose restart gateway-mcp
```

---

## üÜò If Still Having Issues

1. **Reboot in normal mode**

   ```bash
   reboot
   ```

2. **Check logs after reboot**

   ```bash
   dmesg | tail -100
   docker-compose logs --tail=50
   ```

3. **Consider managed database**

   - Move PostgreSQL to DigitalOcean Managed Database
   - Frees up ~150MB

4. **Use Gradient Platform**
   - Offload LLM inference
   - Reduce agent memory footprint

---

## üèóÔ∏è Long-Term Consolidation Plan (Phase 2)

**Goal:** Reduce from 11 containers to 3 containers (65% RAM reduction)

### Architecture Redesign Options

**Option A: Single Synchronous Workflow**

- All agents as nodes in one LangGraph workflow
- Sequential execution with conditional routing
- Simplest implementation, lowest memory

**Option B: Async Multi-Agent System**

- Multiple LangGraph workflows that can run concurrently
- Message-based coordination between agents
- More flexibility, slightly higher memory

**Decision:** TBD - Will iterate on architecture after recovery

### Infrastructure Components (Implementation-Agnostic)

**1. LangGraph/LangChain Integration**

- Replace custom orchestrator with LangGraph workflow engine
- PostgreSQL checkpointer for state management
- Automatic trace generation

**2. Qdrant Cloud Integration**

- Remove local Qdrant container (~256MB savings)
- Use existing cloud cluster (already configured)
- Vector storage for context retrieval

**3. Memory Management**

- LangChain ConversationBufferMemory for chat history
- VectorStoreRetrieverMemory for semantic context
- Replace custom RAG service with built-in patterns

**4. Consolidation Targets**

- Remove: rag-context, state-persistence (replaced by LangGraph)
- Remove: Local Qdrant (use cloud)
- Keep: postgres (for checkpointing), gateway-mcp (Linear OAuth)
- Transform: 6 agents ‚Üí TBD architecture

### Migration Prep (Can Start Now)

1. **Wire orchestrator into LangChain** ‚úì
2. **Integrate Qdrant Cloud SDK** ‚úì
3. **Setup PostgreSQL checkpointer** ‚úì
4. **Add LangChain memory patterns** ‚úì
5. **Decide on sub-agent architecture** ‚è≥

### Expected Savings

- **Current:** 11 containers, ~2.5GB RAM
- **Target:** 3-5 containers, ~850MB-1.2GB RAM
- **Reduction:** 50-65% memory savings

**Next Steps:**

1. Stabilize current droplet (add swap, reboot)
2. Scaffold LangChain/LangGraph infrastructure
3. Integrate Qdrant Cloud
4. Test locally before deploying
